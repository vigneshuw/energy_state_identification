{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b0a7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T05:51:14.356222Z",
     "start_time": "2021-06-08T05:51:13.143709Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155b566",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "- The architecture for a single 1D-CNN model.\n",
    "- Ability to tune the hyper-parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc77730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T06:03:02.799976Z",
     "start_time": "2021-06-08T06:03:02.772121Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_1DCNN_model(layers, counts, act_func, learning_rate, input_shape):\n",
    "\n",
    "    # Ensure that the arguments entered are correct\n",
    "    assert (isinstance(layers, tuple) and isinstance(counts, tuple) and isinstance(input_shape,\n",
    "            tuple) and isinstance(act_func, tuple)), (\"The layers, counts, act_func and input_shape arguments of the function should be tuples\")\n",
    "    assert (len(layers) == len(counts)\n",
    "            ), (\"The length of the layer and counts arguments must be equal\")\n",
    "    for i in zip(layers, counts):\n",
    "        assert (isinstance(i[1], tuple)), (\"The items within counts must be a tuple\")\n",
    "        assert (isinstance(i[0], str)), (\"The items within the layers argument must be a string\")\n",
    "\n",
    "    # Creating a sequential model\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Checking for a flatenning layer before dense layer\n",
    "    flatten_layer_check = 0\n",
    "\n",
    "    # Adding layers and filter to the sequential model depending on the arguments\n",
    "    for index, layer in enumerate(layers):\n",
    "        # The first layer should contain the input shape\n",
    "        if index == 0:\n",
    "            feature_maps, kernel = counts[index]\n",
    "            model.add(keras.layers.Conv1D(feature_maps, kernel, activation=act_func[0], padding=\"same\", input_shape=input_shape))\n",
    "            continue\n",
    "            \n",
    "        # If it is a convolution layer\n",
    "        if layer == \"Conv1D\":\n",
    "            feature_maps, kernel = counts[index]\n",
    "            model.add(keras.layers.Conv1D(feature_maps, kernel, activation=act_func[0], padding='same'))\n",
    "        # For the layer BatchNormalization\n",
    "        elif layer == \"BatchNormalization\":\n",
    "            value = counts[index][0]\n",
    "            if value is not None:\n",
    "                raise ValueError(\"No slot specified for BN layer index\")\n",
    "            model.add(keras.layers.BatchNormalization())\n",
    "        # For the layer LayerNormalization\n",
    "        elif layer == \"LayerNormalization\":\n",
    "            value = counts[index][0]\n",
    "            if value is not None:\n",
    "                raise ValueError(\"No slot specified for LN layer index\")\n",
    "            model.add(keras.layers.LayerNormalization())\n",
    "        # For the layer MaxPooling1D\n",
    "        elif layer == \"MaxPooling1D\":\n",
    "            kernel = counts[index][0]\n",
    "            model.add(keras.layers.MaxPooling1D(kernel))\n",
    "        # For the layer GlobalAveragePooling1D\n",
    "        elif layer == \"GlobalAveragePooling1D\":\n",
    "            value = counts[index][0]\n",
    "            if value is not None:\n",
    "                raise ValueError (\"No slot specified for BN layer index\")\n",
    "            model.add(keras.layers.GlobalAveragePooling1D())\n",
    "        # For the layer Dense\n",
    "        elif (layer == \"Dense\") and (index != len(layers) - 1):\n",
    "            # Check to ensure that you have called Flatten before calling Dense\n",
    "            if layers[index - 1] == \"Flatten\" or flatten_layer_check:\n",
    "                flatten_layer_check = 1\n",
    "                neurons = counts[index][0]\n",
    "                model.add(keras.layers.Dense(neurons, activation=act_func[0]))\n",
    "            else:\n",
    "                sys.stdout.write(\"Dense layer applied before a flattening layer\")\n",
    "                sys.exit(1)\n",
    "        # For the Flatten layer\n",
    "        elif layer == \"Flatten\":\n",
    "            value = counts[index][0]\n",
    "            if value is not None:\n",
    "                raise ValueError (\"No slot specified for Flatten layer index\")\n",
    "            model.add(keras.layers.Flatten())\n",
    "            flatten_layer_check = 1\n",
    "        # For the Dropout layer\n",
    "        elif layer == \"Dropout\":\n",
    "            percent = counts[index][0]\n",
    "            model.add(keras.layers.Dropout(percent))\n",
    "        # For the layer Dense at the end\n",
    "        elif (layer == \"Dense\") and (index == len(layers) - 1):\n",
    "            classes = counts[index][0]\n",
    "            model.add(keras.layers.Dense(classes, activation=act_func[1]))\n",
    "        else:\n",
    "            sys.stdout.write(f'The mentioned layer is not available -- {layer}')\n",
    "            sys.exit(1)\n",
    "            \n",
    "    # The model returned is uncompiled \n",
    "    return model\n",
    "\n",
    "\n",
    "class ModelTuner(kt.HyperModel):\n",
    "    \n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    # It has to be build\n",
    "    def build(self, hp):\n",
    "        # Defining a sequential model\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # Add the input layer and keep it fixed\n",
    "        model.add(tf.keras.layers.Conv1D(64, 3, activation=\"relu\", padding=\"same\", input_shape=self.input_shape))\n",
    "        \n",
    "        # The MainUnit that gets repeated\n",
    "        for i in range(hp.Int(\"main_units\", 3, 10)):\n",
    "            for j in range(hp.Int(\"layers\", 2, 5)):\n",
    "                model.add(tf.keras.layers.Conv1D(hp.Choice(\"feature_units_\" + str(i) + \"-\" + str(j), [128, 256, 512, 1024]), \n",
    "                                                hp.Int(\"kernel_units_\" + str(i) + \"-\" + str(j), 3, 7, step=2), activation=\"relu\", padding=\"same\"))\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "            model.add(tf.keras.layers.MaxPooling1D(hp.Int(\"maxpool_units_\" + str(i), 2, 6, step=2)))\n",
    "            \n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(512, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dropout(hp.Float(\"dropout\", 0.1, 0.7, step=0.2)))\n",
    "        model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "        model.add(tf.keras.layers.Dense(self.num_classes, activation=\"softmax\"))\n",
    "        \n",
    "        adam = tf.keras.optimizers.Adam(lr=hp.Choice('learning_rate', values=[0.0001, 0.001, 0.01]))\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2bdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
