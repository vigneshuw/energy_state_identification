{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7549c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:43:35.306373Z",
     "start_time": "2021-07-30T07:43:35.290743Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To enable faster auto-complete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed08d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:43:36.835514Z",
     "start_time": "2021-07-30T07:43:35.509264Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf \n",
    "import re\n",
    "import numpy as np\n",
    "import eli5\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from tensorflow import keras\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083b69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:43:36.966868Z",
     "start_time": "2021-07-30T07:43:36.884031Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the GPU to be used \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    # Restrict tensor flow to use GPU-1\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Set GPUs before initializing\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ad0526",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Note**\n",
    "- Some cells are converted to raw notebook and some are code cells\n",
    "- The raw cells corresponds to particular type of model, so if you need to use those, convert them back to code cell from the raw cell\n",
    "- Make sure the correct sets of cells are enabled before running the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf0a8a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88b56e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:26:08.255557Z",
     "start_time": "2021-07-30T07:26:08.250791Z"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Seperate Model Data\n",
    "\n",
    "- Data for the models if they were built seperately"
   ]
  },
  {
   "cell_type": "raw",
   "id": "346f135c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T04:37:32.359860Z",
     "start_time": "2021-07-30T04:37:32.212370Z"
    },
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "data_dir = os.path.join(os.getcwd(), \"model_data\", \"axis\")\n",
    "\n",
    "# Model training data\n",
    "y = []\n",
    "axis = {\"xaxis\": 0, \"yaxis\": 1, \"zaxis\": 2, \"baxis\": 3, \"caxis\": 4}\n",
    "for index, file in enumerate(os.listdir(data_dir)):\n",
    "    data = np.load(os.path.join(data_dir, file))\n",
    "    # X\n",
    "    if index == 0:\n",
    "        X = data#[:, :, 2:][:, :, np.newaxis]\n",
    "    else: \n",
    "        X = np.append(X, data, axis=0)\n",
    "    \n",
    "    # y\n",
    "    temp = [True if re.search(file[0:5] + \"*\", x) else False for x in axis.keys()]\n",
    "    class_id = [val for i, val in zip(temp, axis.values()) if i][0]\n",
    "    temp = np.repeat(class_id, data.shape[0])[:, np.newaxis]\n",
    "    if index == 0:\n",
    "        y = temp\n",
    "    else:\n",
    "        y = np.append(y, temp, axis=0)\n",
    "        \n",
    "    sys.stdout.write(f\"The file - {file}, the class_id - {class_id}\\n\")\n",
    "    \n",
    "# Shuffling the data \n",
    "X, y = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9defa63e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-output model Data\n",
    "\n",
    "- The model on the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490d870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:43:38.703505Z",
     "start_time": "2021-07-30T07:43:37.848042Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Directory of the dataset\n",
    "data_dir = os.path.join(os.getcwd(), \"model_data\", \"multi_output_axisfr\")\n",
    "\n",
    "for index1, file in enumerate(os.listdir(data_dir)):\n",
    "    data = np.load(os.path.join(data_dir, file), allow_pickle=True)[()]\n",
    "    \n",
    "    for index2, ((axis, feed_rate), segmented_points) in enumerate(data.items()):\n",
    "        \n",
    "        temp_axis = np.repeat(axis, segmented_points.shape[0])[:, np.newaxis]\n",
    "        temp_fr = np.repeat(feed_rate, segmented_points.shape[0])[:, np.newaxis]\n",
    "    \n",
    "        # part of X and y\n",
    "        if index2 == 0:\n",
    "            # part of y for an axis and all feed rate\n",
    "            part_y_axis = temp_axis\n",
    "            part_y_fr = temp_fr\n",
    "            # part of X\n",
    "            part_X = segmented_points\n",
    "        else:\n",
    "            part_y_axis = np.append(part_y_axis, temp_axis, axis=0)\n",
    "            part_y_fr = np.append(part_y_fr, temp_fr, axis=0)\n",
    "            part_X = np.append(part_X, segmented_points, axis=0)\n",
    "            \n",
    "    if index1 == 0:\n",
    "        # y\n",
    "        y_axis = part_y_axis\n",
    "        y_fr = part_y_fr\n",
    "        # X\n",
    "        X = part_X\n",
    "    else:\n",
    "        y_axis = np.append(y_axis, part_y_axis, axis=0)\n",
    "        y_fr = np.append(y_fr, part_y_fr, axis=0)\n",
    "        X = np.append(X, part_X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8151359",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading the model\n",
    "\n",
    "- Loading the model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ec1ec",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Seperate Model Weights\n",
    "- If the models were developed seperately"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d44dff41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T04:37:34.153696Z",
     "start_time": "2021-07-30T04:37:33.983670Z"
    },
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "# Check the right model type\n",
    "is_multi_output = False\n",
    "\n",
    "model_save_name = \"axis_detection_ov0.5_w85_nTrue.h5\"\n",
    "model_dir_name = \"axis_detection\"\n",
    "model_save_fp = os.path.join(os.getcwd(), \"model_weights\", model_dir_name, model_save_name)\n",
    "\n",
    "# Load the model using keras\n",
    "model =  keras.models.load_model(model_save_fp)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e7e93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-output model Weights\n",
    "\n",
    "- The model in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931039df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:43:41.886636Z",
     "start_time": "2021-07-30T07:43:41.538165Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check the right model type\n",
    "is_multi_output = True\n",
    "\n",
    "# The folder time\n",
    "folder_time = \"2021-07-28T00:07:46.613812\"\n",
    "\n",
    "# Select the model to load\n",
    "load_file = \"multi-ouput_KFold-6_model.h5\"\n",
    "# Load the selected model \n",
    "model = keras.models.load_model(os.path.join(os.getcwd(), \"model_weights\", \"multi_output_ax-fr\", folder_time, load_file))\n",
    "# Need compilation to change the accuracy metric - tensorflow issue\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss={\"axis_detection\": \"sparse_categorical_crossentropy\", \"feed_rate_prediction\": \"mse\"}, \n",
    "              metrics={\"axis_detection\": \"accuracy\"}, loss_weights=[1, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debfddc0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Baseline prediction\n",
    "\n",
    "-  To verify the model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d16fb6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Seperate model prediction"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69ffeab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T04:37:41.276019Z",
     "start_time": "2021-07-30T04:37:35.276166Z"
    },
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "score = model.evaluate(X, y)\n",
    "sys.stdout.write(\"Baseline score: {}\\n\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3a734",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Multi-output model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c161b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:44:03.325951Z",
     "start_time": "2021-07-30T07:43:43.931823Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X, {\"axis_detection\": y_axis, \"feed_rate_prediction\": y_fr})\n",
    "sys.stdout.write(\"Baseline score: {}\\n\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f546d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Permutation Importance\n",
    "\n",
    "- Randomly permute the data. One column at a time\n",
    "- Followed by making a prediction\n",
    "- Determine the impact on the model's performance for each column that is permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d65f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:44:11.846730Z",
     "start_time": "2021-07-30T07:44:11.842290Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Know the data\n",
    "print(\"X: {}\".format(X.shape))\n",
    "print(\"y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204413c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:44:14.514897Z",
     "start_time": "2021-07-30T07:44:14.511303Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary of important features\n",
    "feature_importance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c72d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T07:54:57.870776Z",
     "start_time": "2021-07-30T07:45:34.831930Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_features = 3\n",
    "feature_X_dict = {}\n",
    "num_iterations = 10\n",
    "\n",
    "# Run for certain number of iterations\n",
    "for iteration in range(num_iterations):\n",
    "\n",
    "    # Keep track of the features that are to be shuffled\n",
    "    for index, feature_index in enumerate(range(num_features)):\n",
    "        feature_X_dict[feature_index] = copy.deepcopy(X[:, :, feature_index])\n",
    "\n",
    "    # Feature shuffling\n",
    "    mod_feature_X_dict = {}\n",
    "    temp = copy.deepcopy(feature_X_dict)\n",
    "    for index, feature_index in enumerate(range(num_features)):\n",
    "\n",
    "        # Select the feature to shuffle\n",
    "        # Use deep copy else it will shuffle in place\n",
    "        selected_feature = copy.deepcopy(feature_X_dict[feature_index])\n",
    "        # Shuffle the selected feature\n",
    "        np.random.shuffle(selected_feature)\n",
    "\n",
    "        # Put the shuffled item back\n",
    "        temp[feature_index] = selected_feature\n",
    "\n",
    "        # Put the whole data in a dict\n",
    "        mod_feature_X_dict[feature_index] = temp\n",
    "\n",
    "        # Reset the temp\n",
    "        temp = copy.deepcopy(feature_X_dict)\n",
    "\n",
    "\n",
    "    # Compare the data to ensure it is all good\n",
    "    # The original dictionary\n",
    "    sys.stdout.write('Getting a value of 0.0 => arrays are similar\\n')\n",
    "    for feature_index in feature_X_dict.keys():\n",
    "        sys.stdout.write(f\"{feature_index} - {np.sum(X[:, :, feature_index] - feature_X_dict[feature_index])}\\n\")\n",
    "\n",
    "    for feature_index in mod_feature_X_dict.keys():\n",
    "        sys.stdout.write(f\"=={feature_index}==\\n\")\n",
    "        for feature_index2 in mod_feature_X_dict[feature_index].keys():\n",
    "            sys.stdout.write(f\"{feature_index} - {np.sum(X[:, :,feature_index2] - mod_feature_X_dict[feature_index][feature_index2])} || \")\n",
    "        sys.stdout.write(\"\\n\")\n",
    "\n",
    "\n",
    "    # Computing the score\n",
    "    feature_importance[iteration+1] = {}\n",
    "    for feature in range(num_features):\n",
    "\n",
    "        # Select the data dict\n",
    "        mod_X_dict = mod_feature_X_dict[feature]\n",
    "\n",
    "        # Put the data together\n",
    "        for key in sorted(mod_X_dict.keys()):\n",
    "            if key == 0:\n",
    "                mod_X = mod_X_dict[key][:, :, np.newaxis]\n",
    "            else:\n",
    "                mod_X = np.concatenate((mod_X, mod_X_dict[key][:, :, np.newaxis]), axis=2)\n",
    "\n",
    "        # Predict the model\n",
    "        if is_multi_output:\n",
    "            columns = [\"feature\", \"loss\", \"axis_detection_loss\", \"feed_rate_prediction_loss\", \"axis_detection_accuracy\"]\n",
    "            score = model.evaluate(mod_X, {\"axis_detection\": y_axis, \"feed_rate_prediction\": y_fr})\n",
    "        else:\n",
    "            columns = [\"feature\", \"loss\", \"accuracy\"]\n",
    "            score = model.evaluate(mod_X, y)\n",
    "        # Print the results\n",
    "        print(f\"Feature changed - {feature}; Score - {score}\")\n",
    "\n",
    "        feature_importance[iteration+1][feature] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c53546",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:59:13.765089Z",
     "start_time": "2021-07-30T08:59:13.757343Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to df to analyze the model's performance\n",
    "feature_importance_list = []\n",
    "for iteration in sorted(feature_importance.keys()):\n",
    "    \n",
    "    for index, (key, value) in enumerate(feature_importance[iteration].items()):\n",
    "        temp1 = [key, value[0], value[1], value[2], value[3]]\n",
    "        feature_importance_list.append(temp1)\n",
    "        \n",
    "feature_importance_df = pd.DataFrame(feature_importance_list, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94bc781",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:59:14.483305Z",
     "start_time": "2021-07-30T08:59:14.441731Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Describe summary statistics of the df\n",
    "feature_importance_sum_stat = feature_importance_df.groupby(by=\"feature\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fbb998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:59:14.982394Z",
     "start_time": "2021-07-30T08:59:14.966127Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Stats\n",
    "feature_importance_sum_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1995a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:59:19.352829Z",
     "start_time": "2021-07-30T08:59:19.334141Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Only for feedrate prediction\n",
    "feature_importance_sum_stat[\"feed_rate_prediction_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f3006",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T08:59:22.619531Z",
     "start_time": "2021-07-30T08:59:22.515698Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the font properties\n",
    "matplotlib.rcdefaults()\n",
    "font = {'size'   : 10.0}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "labels = [\"Power-Active\", \"Power-Apparent\", 'Power-Reactive']\n",
    "x = np.arange(3) # Label locations\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "# Bar chart\n",
    "rects1 = ax.bar(x - width/2, np.log(feature_importance_sum_stat[\"axis_detection_loss\"][\"mean\"]), width=0.35, label=\"Axis detection loss\")\n",
    "rects2 = ax.bar(x + width/2, np.log(feature_importance_sum_stat[\"feed_rate_prediction_loss\"][\"mean\"]), width=0.35, label=\"Feed rate prediction loss\")\n",
    "ax.set_xlabel(\"Features\")\n",
    "ax.set_ylabel(\"Sparse Categorical Cross-Entropy Loss\")\n",
    "ax.set_title(\"Feature Importance - FR Prediction\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"feature_imp.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d3c88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}