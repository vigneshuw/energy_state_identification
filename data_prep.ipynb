{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87235e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:00:08.395551Z",
     "start_time": "2021-07-26T20:00:08.379883Z"
    }
   },
   "outputs": [],
   "source": [
    "# To enable faster auto-complete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6cf97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:00:09.010932Z",
     "start_time": "2021-07-26T20:00:08.648542Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313ec4f5",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Two different dataset was created for model development\n",
    "\n",
    "- Axis detection model \n",
    "\n",
    "- Feed rate prediction model\n",
    "\n",
    "Both of them use the same set of features. The features list can be modified as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97055a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:00:09.820902Z",
     "start_time": "2021-07-26T20:00:09.815772Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_create_dir(dir_name):\n",
    "    if os.path.isdir(os.path.join(os.getcwd(), \"model_data\", dir_name)):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(os.path.join(os.getcwd(), \"model_data\", dir_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95535f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:00:17.828631Z",
     "start_time": "2021-07-26T20:00:17.824419Z"
    }
   },
   "outputs": [],
   "source": [
    "# Segmentation parameters\n",
    "overlap_rate = 0.50\n",
    "segment_seconds = 5\n",
    "window_size = segment_seconds * 17\n",
    "save_dir_name = \"axis\"\n",
    "normalization_required = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcac28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T20:00:25.150282Z",
     "start_time": "2021-07-26T20:00:25.145043Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data file location\n",
    "base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "dir_loc = os.path.join(base_dir, \"data\", \"establishing_baseline\")\n",
    "\n",
    "# The columns to read from data set\n",
    "cols_list = [\"power_active_all\", \"power_apparent_all\", \"power_reactive_all\", \"Feed_Rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b50ab",
   "metadata": {},
   "source": [
    "## Axis detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ef57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T21:00:06.695473Z",
     "start_time": "2021-07-26T20:59:07.050577Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(dir_loc):\n",
    "    # Get the file name\n",
    "    file_name = os.path.join(dir_loc, file, \"dataset_model.csv\")\n",
    "    \n",
    "    # Open the file using pandas\n",
    "    df = pd.read_csv(file_name, header=\"infer\", sep=\",\",  usecols=cols_list)\n",
    "    df = df.dropna()\n",
    "    df = df[df['Feed_Rate'] != 0]\n",
    "    df = df[cols_list[0:-1]]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    if normalization_required:\n",
    "        scaler = StandardScaler().fit(df)\n",
    "        temp = scaler.transform(df)\n",
    "        df = pd.DataFrame(temp, columns=cols_list[0:-1])\n",
    "    \n",
    "    # Get the total number of rows to segment\n",
    "    sample_points = math.floor(df.index[-1])\n",
    "    \n",
    "    starting_points = np.arange(0, sample_points, int(window_size * (1 - overlap_rate))).astype('uint32')\n",
    "    for index, i in enumerate(starting_points):\n",
    "        \n",
    "        # Start the segmentation process\n",
    "        if (i + window_size) < sample_points:\n",
    "            segmented_points = copy.deepcopy(df.iloc[i : (i + window_size)])\n",
    "            segmented_points = segmented_points.to_numpy()\n",
    "            # Appending to numpy arrays\n",
    "            if index == 0:\n",
    "                segmented_data = segmented_points[np.newaxis, :, :]\n",
    "            else:\n",
    "                segmented_data = np.append(segmented_data, segmented_points[np.newaxis, :, :], axis=0)\n",
    "                \n",
    "    # Save the file\n",
    "    check_create_dir(save_dir_name)\n",
    "    save_file_name = file[0:5] + \"_af\" + \"_ov\" + str(overlap_rate) + \"_w\" + str(window_size) + \"_n\" + str(normalization_required)\n",
    "    np.save(os.path.join(os.getcwd(), \"model_data\", save_dir_name, save_file_name), segmented_data)\n",
    "    \n",
    "    # Display output for completion\n",
    "    sys.stdout.write(f\"Completed processing - {file}\\n\")\n",
    "    sys.stdout.write(f\"The shape of the data is {segmented_data.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2164a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T19:23:36.723345Z",
     "start_time": "2021-07-06T19:23:36.717472Z"
    }
   },
   "source": [
    "## Feed rate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04c35a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T21:05:52.293038Z",
     "start_time": "2021-07-08T21:05:38.869361Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "save_dir_name = \"feedrate\"\n",
    "\n",
    "for file in os.listdir(dir_loc):\n",
    "    # Get the file name\n",
    "    file_name = os.path.join(dir_loc, file, \"dataset_model.csv\")\n",
    "    \n",
    "    # Open the file using pandas\n",
    "    df = pd.read_csv(file_name, header=\"infer\", sep=\",\", usecols=cols_list)\n",
    "    df = df.dropna()\n",
    "    df = df[df[\"Feed_Rate\"] != 0]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Taking out the feed rate \n",
    "    df_feed = df[cols_list[-1]]\n",
    "    df = df[cols_list[0:-1]]\n",
    "    \n",
    "    # Normalizing the dataset\n",
    "    if normalization_required:\n",
    "        scaler = StandardScaler().fit(df)\n",
    "        temp = scaler.transform(df)\n",
    "        df = pd.DataFrame(temp, columns=cols_list[0:-1])\n",
    "    # Putting the feed rate back in\n",
    "    df[\"Feed_Rate\"] = df_feed\n",
    "        \n",
    "    # Grouping by the feed rates\n",
    "    df_group = df.groupby('Feed_Rate')\n",
    "    feed_rates = list(df_group.groups)\n",
    "    \n",
    "    # For each group get the appropriate data\n",
    "    data_dict = {}\n",
    "    for feed_rate in feed_rates:\n",
    "        \n",
    "        # Segment the data within each feed rate\n",
    "        # Get the grouped data into a dict\n",
    "        temp = df_group.get_group(feed_rate)\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        df = temp[cols_list[0:-1]]\n",
    "\n",
    "        # Get the total number of rows to segment\n",
    "        sample_points = math.floor(df.index[-1])\n",
    "    \n",
    "        starting_points = np.arange(0, sample_points, int(window_size * (1 - overlap_rate))).astype('uint32')\n",
    "        for index, i in enumerate(starting_points):\n",
    "\n",
    "            # Start the segmentation process\n",
    "            if (i + window_size) < sample_points:\n",
    "                segmented_points = copy.deepcopy(df.iloc[i : (i + window_size)])\n",
    "                segmented_points = segmented_points.to_numpy()\n",
    "                # Appending to numpy arrays\n",
    "                if index == 0:\n",
    "                    segmented_data = segmented_points[np.newaxis, :, :]\n",
    "                else:\n",
    "                    segmented_data = np.append(segmented_data, segmented_points[np.newaxis, :, :], axis=0)\n",
    "\n",
    "        data_dict[feed_rate] = segmented_data\n",
    "        \n",
    "    # Save the data for each axis seperately\n",
    "    check_create_dir(save_dir_name)\n",
    "    save_file_name = file[0:5] + \"_feeddict\" + \"_ov\" + str(overlap_rate) + \"_w\" + str(window_size) + \"_n\" + str(normalization_required)\n",
    "    np.save(os.path.join(os.getcwd(), \"model_data\", save_dir_name, save_file_name), data_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619659af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T21:05:53.349751Z",
     "start_time": "2021-07-08T21:05:53.343676Z"
    }
   },
   "source": [
    "## Multi-output [Axis and Feed rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813baef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T07:30:48.748089Z",
     "start_time": "2021-07-09T07:30:48.744049Z"
    }
   },
   "outputs": [],
   "source": [
    "# Segmentation parameters\n",
    "overlap_rate = 0.50\n",
    "segment_seconds = 5\n",
    "window_size = segment_seconds * 17\n",
    "normalization_required = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac325b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T07:31:48.567293Z",
     "start_time": "2021-07-09T07:31:35.733701Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dir_name = \"multi_output_axisfr\"\n",
    "\n",
    "# Class association for axis\n",
    "axis = {\"xaxis\": 0, \"yaxis\": 1, \"zaxis\": 2, \"baxis\": 3, \"caxis\": 4}\n",
    "\n",
    "for file in os.listdir(dir_loc):\n",
    "    # Get the file name\n",
    "    file_name = os.path.join(dir_loc, file, \"dataset_model.csv\")\n",
    "    \n",
    "    # Open the file using pandas\n",
    "    df = pd.read_csv(file_name, header=\"infer\", sep=\",\", usecols=cols_list)\n",
    "    df = df.dropna()\n",
    "    df = df[df[\"Feed_Rate\"] != 0]\n",
    "    df = df.reset_index(drop=True)\n",
    "    # Taking out the feed rate \n",
    "    df_feed = df[cols_list[-1]]\n",
    "    df = df[cols_list[0:-1]]\n",
    "    \n",
    "    # Normalizing the dataset\n",
    "    if normalization_required:\n",
    "        scaler = StandardScaler().fit(df)\n",
    "        temp = scaler.transform(df)\n",
    "        df = pd.DataFrame(temp, columns=cols_list[0:-1])\n",
    "    # Putting the feed rate back in\n",
    "    df[\"Feed_Rate\"] = df_feed\n",
    "    \n",
    "    # Grouping by the feed rates\n",
    "    df_group = df.groupby('Feed_Rate')\n",
    "    feed_rates = list(df_group.groups)\n",
    "    \n",
    "    # For each group get the appropriate data\n",
    "    data_dict = {}\n",
    "    for feed_rate in feed_rates:\n",
    "        \n",
    "        # Segment the data within each feed rate\n",
    "        # Get the grouped data into a dict\n",
    "        temp = df_group.get_group(feed_rate)\n",
    "        temp = temp.reset_index(drop=True)\n",
    "        df = temp[cols_list[0:-1]]\n",
    "\n",
    "        # Get the total number of rows to segment\n",
    "        sample_points = math.floor(df.index[-1])\n",
    "    \n",
    "        starting_points = np.arange(0, sample_points, int(window_size * (1 - overlap_rate))).astype('uint32')\n",
    "        for index, i in enumerate(starting_points):\n",
    "\n",
    "            # Start the segmentation process\n",
    "            if (i + window_size) < sample_points:\n",
    "                segmented_points = copy.deepcopy(df.iloc[i : (i + window_size)])\n",
    "                segmented_points = segmented_points.to_numpy()\n",
    "                # Appending to numpy arrays\n",
    "                if index == 0:\n",
    "                    segmented_data = segmented_points[np.newaxis, :, :]\n",
    "                else:\n",
    "                    segmented_data = np.append(segmented_data, segmented_points[np.newaxis, :, :], axis=0)\n",
    "        \n",
    "        # Create the class id based on the type of axis\n",
    "        temp = [True if re.search(file[0:5] + \"*\", x) else False for x in axis.keys()]\n",
    "        class_id = [val for i, val in zip(temp, axis.values()) if i][0]\n",
    "\n",
    "        data_dict[(class_id, feed_rate)] = segmented_data\n",
    "        \n",
    "    # Save the data for each axis seperately\n",
    "    check_create_dir(save_dir_name)\n",
    "    save_file_name = file[0:5] + \"_axisfeeddict\" + \"_ov\" + str(overlap_rate) + \"_w\" + str(window_size) + \"_n\" + str(normalization_required)\n",
    "    np.save(os.path.join(os.getcwd(), \"model_data\", save_dir_name, save_file_name), data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3cd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T07:41:43.194251Z",
     "start_time": "2021-07-09T07:41:43.178117Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb143e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6eea63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a41dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa219885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cdfe1de",
   "metadata": {},
   "source": [
    "# Rough Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab426dda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T17:04:27.561355Z",
     "start_time": "2021-07-08T17:04:27.556347Z"
    }
   },
   "outputs": [],
   "source": [
    "# The data file location\n",
    "base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "dir_loc = os.path.join(base_dir, \"data\", \"establishing_baseline\")\n",
    "\n",
    "# The columns to read from data set\n",
    "cols_list = [\"power_active_all\", \"power_apparent_all\", \"power_reactive_all\", \"Feed_Rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3639798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T17:04:29.633635Z",
     "start_time": "2021-07-08T17:04:27.785779Z"
    }
   },
   "outputs": [],
   "source": [
    "file = \"xaxis_20-20-980_A50\"\n",
    "# Get the file name\n",
    "file_name = os.path.join(dir_loc, file, \"dataset_model.csv\")\n",
    "\n",
    "# Open the file using pandas\n",
    "df = pd.read_csv(file_name, header=\"infer\", sep=\",\",  usecols=cols_list)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea251a5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T17:04:32.488064Z",
     "start_time": "2021-07-08T17:04:32.467224Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df[\"Feed_Rate\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23c1ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T15:47:27.992118Z",
     "start_time": "2021-07-08T15:47:27.985016Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[cols_list[0:]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfdc13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T22:31:17.163384Z",
     "start_time": "2021-07-07T22:31:17.112005Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(df)\n",
    "a = scaler.transform(df)\n",
    "df = pd.DataFrame(a, columns=cols_list[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956af48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T15:47:40.820742Z",
     "start_time": "2021-07-08T15:47:40.816916Z"
    }
   },
   "outputs": [],
   "source": [
    "dfg = df.groupby(by=\"Feed_Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5669d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T16:50:30.336850Z",
     "start_time": "2021-07-08T16:50:30.317413Z"
    }
   },
   "outputs": [],
   "source": [
    "dfg.get_group(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c768e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T17:04:45.074577Z",
     "start_time": "2021-07-08T17:04:45.068535Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Something\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774d1170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T17:06:42.643688Z",
     "start_time": "2021-07-08T17:06:42.635042Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Feed_Rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b479158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
