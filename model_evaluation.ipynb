{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c06eea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:46:27.066766Z",
     "start_time": "2021-07-30T06:46:25.694506Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils import data_augmentation\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import utils\n",
    "\n",
    "font = {\n",
    "    'family' : 'normal',\n",
    "    'weight': 'normal',\n",
    "    'size': 18\n",
    "}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8be26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:46:31.391692Z",
     "start_time": "2021-07-30T06:46:31.314476Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the GPU to be used \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    # Restrict tensor flow to use GPU-1\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Set GPUs before initializing\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e51960",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multi-output model evaluation and Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a4942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T16:27:04.025236Z",
     "start_time": "2021-07-26T16:27:04.021505Z"
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data without oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c7610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:48:00.605502Z",
     "start_time": "2021-07-30T06:47:59.787619Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Directory of the dataset\n",
    "data_dir = os.path.join(os.getcwd(), \"model_data\", \"multi_output_axisfr\")\n",
    "\n",
    "for index1, file in enumerate(os.listdir(data_dir)):\n",
    "    data = np.load(os.path.join(data_dir, file), allow_pickle=True)[()]\n",
    "    \n",
    "    for index2, ((axis, feed_rate), segmented_points) in enumerate(data.items()):\n",
    "        \n",
    "        temp_axis = np.repeat(axis, segmented_points.shape[0])[:, np.newaxis]\n",
    "        temp_fr = np.repeat(feed_rate, segmented_points.shape[0])[:, np.newaxis]\n",
    "    \n",
    "        # part of X and y\n",
    "        if index2 == 0:\n",
    "            # part of y for an axis and all feed rate\n",
    "            part_y_axis = temp_axis\n",
    "            part_y_fr = temp_fr\n",
    "            # part of X\n",
    "            part_X = segmented_points\n",
    "        else:\n",
    "            part_y_axis = np.append(part_y_axis, temp_axis, axis=0)\n",
    "            part_y_fr = np.append(part_y_fr, temp_fr, axis=0)\n",
    "            part_X = np.append(part_X, segmented_points, axis=0)\n",
    "            \n",
    "    if index1 == 0:\n",
    "        # y\n",
    "        y_axis = part_y_axis\n",
    "        y_fr = part_y_fr\n",
    "        # X\n",
    "        X = part_X\n",
    "    else:\n",
    "        y_axis = np.append(y_axis, part_y_axis, axis=0)\n",
    "        y_fr = np.append(y_fr, part_y_fr, axis=0)\n",
    "        X = np.append(X, part_X, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a75be",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Recovering the training history and scores for verification\n",
    "\n",
    "- To get an idea on the training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The folder time - determine\n",
    "folder_time = \"2022-06-22T22:15:53.705105\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b3397",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select item to load\n",
    "history_path = os.path.join(os.getcwd(), \"model_weights\", \"multi_output_ax-fr\", folder_time, \"training_history\", \"history.pickle\")\n",
    "score_path = os.path.join(os.getcwd(), \"model_weights\", \"multi_output_ax-fr\", folder_time, \"training_history\", \"score.pickle\")\n",
    "\n",
    "with open(history_path, \"rb\") as fh:\n",
    "    history = pickle.load(fh)\n",
    "    \n",
    "with open(score_path, \"rb\") as fh:\n",
    "    score = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c23c51f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=============================== Accuracies ==============================\")\n",
    "print(f\"Maximum axis-detection training accuracy {max(history[0]['axis_detection_accuracy'])}\")\n",
    "print(f\"Maximum axis-detection validation accuracy {max(history[0]['val_axis_detection_accuracy'])}\")\n",
    "\n",
    "print(\"=============================== Losses ==================================\")\n",
    "print(f\"Minimum axis-detection training loss {min(history[0]['axis_detection_loss'])}\")\n",
    "print(f\"Minimum axis-detection validation loss {min(history[0]['val_axis_detection_loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find the index of maximum\n",
    "val_losses = []\n",
    "for kfold in history.keys():\n",
    "    val_losses.append(min(history[kfold][\"val_loss\"]))\n",
    "sys.stdout.write(f\"The validation losses for each of the fold is given by {val_losses}\\n\")\n",
    "sys.stdout.write(f\"The K-fold with the best performance is {val_losses.index(min(val_losses))}\\n\")\n",
    "# Select the fold\n",
    "selected_fold = val_losses.index(min(val_losses))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f6b11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The scores are given below\")\n",
    "print(score[selected_fold])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac9d1e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting model evaluation results\n",
    "\n",
    "- Classification report\n",
    "- F1-Score and associated metrics\n",
    "- Error Histogram\n",
    "- Axis Detection confusion matrix\n",
    "- Feed rate prediction results\n",
    "- Evaluation of the CV fold performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775195e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:53:42.644853Z",
     "start_time": "2021-07-30T06:53:23.812832Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Select the model to load\n",
    "load_file = f\"multi-output_KFold-{selected_fold}_model.h5\"\n",
    "# Load the selected model \n",
    "model = keras.models.load_model(os.path.join(os.getcwd(), \"model_weights\", \"multi_output_ax-fr\", folder_time, load_file))\n",
    "# Need compilation to change the accuracy metric - tensorflow issue\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss={\"axis_detection\": \"sparse_categorical_crossentropy\", \"feed_rate_prediction\": \"mse\"}, \n",
    "              metrics={\"axis_detection\": \"accuracy\"}, loss_weights=[1, 20])\n",
    "\n",
    "model.evaluate(X, {\"axis_detection\": y_axis, \"feed_rate_prediction\": y_fr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdc7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:56:12.182464Z",
     "start_time": "2021-07-30T06:55:58.235425Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predict using the model \n",
    "y_pred = model.predict(X)\n",
    "# Predicting the axis\n",
    "y_pred_axis = np.argmax(y_pred[0], axis=1)\n",
    "# Feed rates\n",
    "y_pred_fr = y_pred[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification Report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8e449",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "target_classes = [\"X\", \"Y\", \"Z\", \"B\", \"C\"]\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_axis, y_pred_axis, target_names=target_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AUC Curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d475c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The AUC score \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Getting the probability scores\n",
    "y_score = y_pred[0]\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Get the score\n",
    "roc_auc = roc_auc_score(y_axis, y_score, average=\"macro\", multi_class=\"ovr\", labels=classes)\n",
    "\n",
    "print(f'The AOC value is {roc_auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### R2 Score for regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407f89a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Regression report\n",
    "# Computation for R^2 and RMSE\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_fr, y_pred_fr)\n",
    "\n",
    "print(f\"The R^2 value for regression is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Error histogram"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8258c39",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "# error histogram\n",
    "error = y_fr - y_pred_fr\n",
    "\n",
    "std = np.std(error)\n",
    "print(f\"The standard deviation is given by {std}\")\n",
    "\n",
    "hist = ax.hist(error, bins=50, range=(-84, +84), histtype=\"bar\", color=\"red\")\n",
    "\n",
    "ax.set_title(\"Error histogram\")\n",
    "ax.set_xlabel(r\"Error $(y_i - \\hat{y}_i)$\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "#fig.savefig(\"error_history.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Error histogram by axis\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the figures\n",
    "fig = plt.figure(figsize=(30, 20))\n",
    "ax = fig.subplots(nrows=2, ncols=3)\n",
    "\n",
    "# Create a dataframe of all Ys\n",
    "y_df = pd.DataFrame(data=np.concatenate((np.expand_dims(y_pred_axis, axis=1), y_pred_fr, y_fr), axis=1), columns=[\"pred_yaxis\", \"pred_yfr\", \"y_fr\"], dtype=\"float32\", copy=True)\n",
    "y_df[\"fr_error\"] = y_df[\"y_fr\"] - y_df[\"pred_yfr\"]\n",
    "y_df_group = y_df.groupby(by=\"pred_yaxis\")\n",
    "\n",
    "axes_conversion = [\"X\", \"Y\", \"Z\", \"B\", \"C\"]\n",
    "row = 0\n",
    "col = 0\n",
    "for index, axis_index in enumerate(y_df_group.groups.keys()):\n",
    "    # Get the error values\n",
    "    error = y_df_group.get_group(axis_index)[\"fr_error\"]\n",
    "\n",
    "    # Normalize the standard deviation if required\n",
    "\n",
    "    # Plot the histogram\n",
    "    hist = ax[row, col].hist(error, bins=50, range=(-100, +100), histtype=\"bar\", color=\"red\")\n",
    "    # Set the title appropriately\n",
    "    ax[row, col].set_title(f\"Error histogram for {axes_conversion[int(axis_index)]}-axis with $\\sigma$ = {np.std(error.to_numpy()).round(decimals=0)}\")\n",
    "    ax[row, col].set_xlabel(r\"Error $(y_i - \\hat{y}_i)$\")\n",
    "    ax[row, col].set_ylabel(\"Frequency\")\n",
    "\n",
    "    # Handle row and col conversions\n",
    "    col += 1\n",
    "    if col > 2:\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "# Delete the un-plotted axis\n",
    "plt.delaxes(ax[-1, -1])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29466e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:56:29.650377Z",
     "start_time": "2021-07-30T06:56:29.368041Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Determining and plotting the confusion matrix\n",
    "class_names = [\"X-axis\", \"Y-axis\", \"Z-axis\", \"B-axis\", \"C-axis\"]\n",
    "con_mat = tf.math.confusion_matrix(labels=y_axis, predictions=y_pred_axis).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1) [:, np.newaxis], decimals=2)\n",
    "con_mat_df = pd.DataFrame(con_mat_norm, index=class_names, columns=class_names)\n",
    "figure = plt.figure(figsize=(10,8))\n",
    "sns.set(font_scale = 2)\n",
    "sns.heatmap(con_mat_df, annot=True, cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "\n",
    "#plt.savefig(\"conmat-temp.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feed rate prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6393b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:56:41.433145Z",
     "start_time": "2021-07-30T06:56:41.200395Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the predicted feed rates \n",
    "results_df = pd.DataFrame({\"axis_act\": np.squeeze(y_axis), \"fr_act\": np.squeeze(y_fr), \"axis_pred\": np.squeeze(y_pred_axis), \"fr_pred\": np.squeeze(y_pred_fr)})\n",
    "temp = results_df.groupby(by=[\"axis_act\", \"fr_act\"])\n",
    "\n",
    "plot_data = {}\n",
    "checked_list = []\n",
    "for index, group in enumerate(temp.groups.keys()):\n",
    "    \n",
    "    if group[0] not in checked_list:\n",
    "        temp2 = temp.get_group(group)\n",
    "        temp2 = temp2[temp2[\"axis_act\"] == temp2[\"axis_pred\"]]\n",
    "        plot_data[group[0]] = np.array([[group[1], temp2[\"fr_pred\"].mean()]])\n",
    "        checked_list.append(group[0])\n",
    "    else:\n",
    "        temp2 = temp.get_group(group)\n",
    "        temp2 = temp2[temp2[\"axis_act\"] == temp2[\"axis_pred\"]]\n",
    "        plot_data[group[0]] = np.append(plot_data[group[0]], np.array([[group[1], temp2[\"fr_pred\"].mean()]]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b96a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:56:47.435138Z",
     "start_time": "2021-07-30T06:56:43.490278Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the font properties\n",
    "matplotlib.rcdefaults()\n",
    "font = {'size'   : 5.0}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# PLotting of the feed rate prediction\n",
    "fig, axs = plt.subplots(5, 1, sharey=False, figsize=(20, 15))\n",
    "\n",
    "for axis in sorted(plot_data.keys()):\n",
    "    \n",
    "    # Get the actual and predicted feed\n",
    "    actual_feed = plot_data[axis][:, 0]\n",
    "    predicted_feed = plot_data[axis][:, 1]\n",
    "    labels = [str(round(x)) for x in actual_feed]\n",
    "    \n",
    "    # PLotting the bar chart\n",
    "    x = np.arange(len(labels)) # the label locations\n",
    "    width = 0.35 # the width of the bars \n",
    "    \n",
    "    rects1 = axs[axis].bar(x - width/2, actual_feed, width, label=\"Actual\")\n",
    "    rects2 = axs[axis].bar(x + width/2, predicted_feed, width, label=\"Predicted\")\n",
    "    \n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    axs[axis].set_xticks(x)\n",
    "    axs[axis].set_xticklabels(labels)\n",
    "    axs[axis].legend(loc=\"upper left\")\n",
    "    \n",
    "    #fig.savefig(\"feed_rate_pred.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e222759",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## CV fold evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5beaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:57:06.771316Z",
     "start_time": "2021-07-30T06:57:06.766181Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score_load_loc = os.path.join(os.getcwd(), \"model_weights\", \"multi_output_ax-fr\", folder_time, \"training_history\", \"score.pickle\")\n",
    "\n",
    "# Load the data\n",
    "with open(score_load_loc, \"rb\") as fhandle:\n",
    "    scores = pickle.load(fhandle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63217b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:57:07.902925Z",
     "start_time": "2021-07-30T06:57:07.895896Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scores, index=[\"cummulative_loss\", \"axis_detection_loss\", \"feed_rate_prediction_loss\", \"axis_detection_accuracy\"])\n",
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c8501",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:57:09.769359Z",
     "start_time": "2021-07-30T06:57:09.738981Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.stdout.write(\"Feed rate prediction MSE\\n\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sys.stdout.write(\"Feed rate prediction RMSE\\n\")\n",
    "df[\"feed_rate_prediction_loss\"] = np.sqrt(df[\"feed_rate_prediction_loss\"])\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef73a67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-30T06:57:14.505029Z",
     "start_time": "2021-07-30T06:57:14.270137Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.stdout.write(\"Feed rate prediction loss\\n\")\n",
    "df[[\"feed_rate_prediction_loss\"]].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sys.stdout.write(\"Axis detection loss\\n\")\n",
    "df[[\"axis_detection_loss\"]].boxplot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sys.stdout.write(\"Axis detection loss\\n\")\n",
    "df[[\"axis_detection_accuracy\"]].boxplot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}